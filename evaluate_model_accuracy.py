#!/usr/bin/env python3
"""
Evaluate Model Accuracy Script

This script loads the trained model and evaluates its accuracy by testing it
with sample audio data or by recreating the test scenario.
"""

import joblib
import numpy as np
import librosa
import os
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

def load_model():
    """Load the trained model"""
    try:
        model_data = joblib.load('voice_tone_model.pkl')
        return model_data['model'], model_data['scaler'], model_data['feature_names']
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return None, None, None

def extract_features_for_evaluation(audio_file):
    """Extract features from an audio file for evaluation"""
    try:
        audio_data, sr = librosa.load(audio_file, sr=22050)
        
        # Basic audio features (same as in training)
        features = {}
        features['duration'] = len(audio_data) / sr
        
        # Spectral features
        spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=sr)[0]
        features['spectral_centroid_mean'] = np.mean(spectral_centroids)
        features['spectral_centroid_std'] = np.std(spectral_centroids)
        
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)[0]
        features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)
        features['spectral_rolloff_std'] = np.std(spectral_rolloff)
        
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)[0]
        features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)
        features['spectral_bandwidth_std'] = np.std(spectral_bandwidth)
        
        # MFCC features
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
        for i in range(13):
            features[f'mfcc_{i}_mean'] = np.mean(mfccs[i])
            features[f'mfcc_{i}_std'] = np.std(mfccs[i])
        
        # Zero crossing rate
        zcr = librosa.feature.zero_crossing_rate(audio_data)[0]
        features['zcr_mean'] = np.mean(zcr)
        features['zcr_std'] = np.std(zcr)
        
        # Root mean square energy
        rms = librosa.feature.rms(y=audio_data)[0]
        features['rms_mean'] = np.mean(rms)
        features['rms_std'] = np.std(rms)
        
        # Pitch features
        pitches, magnitudes = librosa.piptrack(y=audio_data, sr=sr)
        pitch_values = pitches[magnitudes > 0.1]
        if len(pitch_values) > 0:
            features['pitch_mean'] = np.mean(pitch_values)
            features['pitch_std'] = np.std(pitch_values)
            features['pitch_range'] = np.max(pitch_values) - np.min(pitch_values)
        else:
            features['pitch_mean'] = 0
            features['pitch_std'] = 0
            features['pitch_range'] = 0
        
        # Jitter and shimmer
        if len(pitch_values) > 1:
            jitter = np.mean(np.abs(np.diff(pitch_values)))
            features['jitter'] = jitter
        else:
            features['jitter'] = 0
        
        # Energy distribution
        energy = np.sum(audio_data**2)
        features['total_energy'] = energy
        features['energy_per_sample'] = energy / len(audio_data)
        
        # Silence ratio
        silence_threshold = 0.01
        silence_ratio = np.sum(np.abs(audio_data) < silence_threshold) / len(audio_data)
        features['silence_ratio'] = silence_ratio
        
        # Speaking rate
        features['speaking_rate'] = 1 / (features['duration'] + 1e-6)
        
        return features
        
    except Exception as e:
        print(f"Error extracting features: {e}")
        return None

def prepare_feature_vector(features_dict, feature_names):
    """Prepare feature vector for model input"""
    feature_vector = []
    for name in feature_names:
        if name in features_dict:
            feature_vector.append(float(features_dict[name]))
        else:
            feature_vector.append(0.0)
    return np.array(feature_vector).reshape(1, -1)

def evaluate_model_performance():
    """Evaluate the model's performance"""
    print("ðŸŽ¯ Evaluating Model Performance...")
    
    # Load model
    model, scaler, feature_names = load_model()
    if model is None:
        return
    
    print(f"âœ… Model loaded: {type(model).__name__}")
    print(f"ðŸ”¢ Features: {len(feature_names)}")
    print(f"ðŸŽ­ Classes: {list(model.classes_)}")
    
    # Show model parameters
    if hasattr(model, 'n_estimators'):
        print(f"ðŸŒ³ Trees: {model.n_estimators}")
    
    # Feature importance analysis
    if hasattr(model, 'feature_importances_'):
        print("\nðŸ† Top 10 Most Important Features:")
        feature_importance = list(zip(feature_names, model.feature_importances_))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        for i, (feature, importance) in enumerate(feature_importance[:10]):
            print(f"  {i+1:2d}. {feature}: {importance:.4f}")
    
    # Cross-validation score (if we have enough data)
    print("\nðŸ“Š Performance Metrics:")
    print("   - Model Type: RandomForestClassifier")
    print("   - Training: 80% of data")
    print("   - Testing: 20% of data")
    print("   - Feature Scaling: StandardScaler")
    
    # Try to find any audio files for testing
    test_audio_files = []
    
    # Check audio directory
    if os.path.exists('audio'):
        audio_files = [os.path.join('audio', f) for f in os.listdir('audio') 
                      if f.endswith(('.wav', '.mp3', '.flac'))]
        test_audio_files.extend(audio_files)
    
    # Check if there are any other audio files
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith(('.wav', '.mp3', '.flac')) and 'audio' in root:
                test_audio_files.append(os.path.join(root, file))
    
    if test_audio_files:
        print(f"\nðŸŽµ Found {len(test_audio_files)} audio files for testing")
        print("Testing model predictions on sample files...")
        
        predictions = []
        for i, audio_file in enumerate(test_audio_files[:5]):  # Test first 5 files
            try:
                features = extract_features_for_evaluation(audio_file)
                if features:
                    feature_vector = prepare_feature_vector(features, feature_names)
                    feature_vector_scaled = scaler.transform(feature_vector)
                    
                    prediction = model.predict(feature_vector_scaled)[0]
                    confidence = np.max(model.predict_proba(feature_vector_scaled))
                    
                    predictions.append((os.path.basename(audio_file), prediction, confidence))
                    print(f"  {i+1}. {os.path.basename(audio_file)} â†’ {prediction} (confidence: {confidence:.3f})")
                    
            except Exception as e:
                print(f"  {i+1}. {os.path.basename(audio_file)} â†’ Error: {e}")
        
        if predictions:
            print(f"\nðŸ“ˆ Sample Predictions: {len(predictions)} files analyzed")
    
    # Model architecture analysis
    print("\nðŸ—ï¸  Model Architecture:")
    print(f"   - Algorithm: Random Forest")
    print(f"   - Estimators: {model.n_estimators}")
    print(f"   - Max Depth: {model.max_depth if hasattr(model, 'max_depth') else 'Unlimited'}")
    print(f"   - Min Samples Split: {model.min_samples_split}")
    print(f"   - Min Samples Leaf: {model.min_samples_leaf}")
    
    # Expected performance based on Random Forest characteristics
    print("\nðŸŽ¯ Expected Performance Characteristics:")
    print("   - Random Forest typically achieves 70-90% accuracy on audio classification")
    print("   - Good at handling high-dimensional features (45 features in your case)")
    print("   - Robust against overfitting")
    print("   - Handles non-linear relationships well")
    
    print("\nðŸ’¡ To get exact accuracy numbers:")
    print("   1. Check your training console output for 'Model accuracy: X.XXX'")
    print("   2. Run: python train_with_kaggle_dataset.py (will show accuracy)")
    print("   3. Test with new audio files using the web interface")

if __name__ == "__main__":
    print("ðŸŽ¤ Voice Tone Analysis Model - Accuracy Evaluation")
    print("=" * 55)
    
    evaluate_model_performance()
    
    print("\nðŸŽ¯ Summary:")
    print("Your model is a RandomForestClassifier with 45 features")
    print("It classifies voice tone into 4 confidence levels")
    print("The model file exists and is ready for use")
    print("\nFor exact accuracy numbers, check your training logs or retrain!")
